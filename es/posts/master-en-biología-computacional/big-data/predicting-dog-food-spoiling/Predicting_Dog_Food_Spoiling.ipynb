{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIC9iWzuwDoX"
   },
   "source": [
    "You've been hired by a dog food company to try to predict why some batches of their dog food are spoiling much quicker than intended! Unfortunately this Dog Food company hasn't upgraded to the latest machinery, meaning that the amounts of the five preservative chemicals they are using can vary a lot, but which is the chemical that has the strongest effect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olXmqHZBwEQk"
   },
   "source": [
    "The dog food company first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. The food scientists believe one of the A,B,C, or D preservatives is causing the problem, but need your help to figure out which one! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEDZ4_1GwaRd"
   },
   "source": [
    "First, we need to create the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y4Ebx4LtDDr1"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://mirrors.sonic.net/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
    "!tar xzf spark-3.1.2-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wcm47e_wmlH"
   },
   "source": [
    "Afterwards, we can read the file and inspect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4Si63Xz5whK6",
    "outputId": "63099a9b-2f6c-4f4b-f293-a9d2ca9f1e77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Spoiled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>5.53469387755102</td>\n",
       "      <td>5.504081632653061</td>\n",
       "      <td>9.126530612244897</td>\n",
       "      <td>5.579591836734694</td>\n",
       "      <td>0.2857142857142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>2.9515204234399057</td>\n",
       "      <td>2.8537966089662063</td>\n",
       "      <td>2.0555451971054275</td>\n",
       "      <td>2.8548369309982857</td>\n",
       "      <td>0.45221563164613465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                   A  ...                   D              Spoiled\n",
       "0   count                 490  ...                 490                  490\n",
       "1    mean    5.53469387755102  ...   5.579591836734694   0.2857142857142857\n",
       "2  stddev  2.9515204234399057  ...  2.8548369309982857  0.45221563164613465\n",
       "3     min                   1  ...                   1                  0.0\n",
       "4     max                  10  ...                  10                  1.0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please drop the file in the environments 'Files' panel\n",
    "df = spark.read.options(header=\"true\", inferSchema=\"true\").csv(\"/content/dog_food.csv\")\n",
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1jFQQKr4_iV"
   },
   "source": [
    "The idea for this assignment is to use Tree Methods to find underlying patterns in data, preventing the model from making undue assumptions about the data itself and letting it speak by itself. In any case, and as with the previous models, we must first assemble a Vector with a \"features\" and a \"label\" tag so that it can be processed by Spark. For more commented code, please see other assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LEHNISHgwxnv"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, Imputer\n",
    "assembler = VectorAssembler(inputCols= [e for e in df.columns if e not in ('Spoiled')]  , outputCol='features', handleInvalid='skip')\n",
    "output = assembler.transform(df)\n",
    "imputer = Imputer(inputCols=['Spoiled'], outputCols=['label'], strategy='mean')\n",
    "imputer_model = imputer.fit(output)\n",
    "output = imputer_model.transform(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCsB2pyI5vEi"
   },
   "source": [
    "As always, we divide the data into a train and a test set, so that we can test the metrics and see if everything went OK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dZqV_Azn1ZxI"
   },
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9N7fiYugCEyR"
   },
   "source": [
    "We are using three different tree methods, which come bundled with spark:\n",
    "\n",
    "\n",
    "* [Decission Tree Classifier](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.classification.DecisionTreeClassifier.html): It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves).\n",
    "* [Random Forest Classifier](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html):  For classification tasks, the output of the random forest is the class selected by most trees. For regression tasks, the mean or average prediction of the individual trees is returned. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "* [Gradient Boosted Trees](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.classification.GBTClassifier.html): It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees. When a decision tree is the weak learner, the resulting algorithm is called gradient-boosted trees; it usually outperforms random forest.\n",
    "\n",
    "We will use the three methods to find if their results match, and to pick the most accurate of the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "452Pwvng0iOk"
   },
   "outputs": [],
   "source": [
    "#Fist, we alias the methods to make them easier to call\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier(numTrees = 100)\n",
    "gbt = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J4xge9tV1tap"
   },
   "outputs": [],
   "source": [
    "#We fit the three models\n",
    "dtc_model = dtc.fit(train)\n",
    "rfc_model = rfc.fit(train)\n",
    "gbt_model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PDt0N0Yu2byX"
   },
   "outputs": [],
   "source": [
    "#And get their predictions\n",
    "dtc_preds = dtc_model.transform(test)\n",
    "rfc_preds = rfc_model.transform(test)\n",
    "gbt_preds = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OZxU3CrErur"
   },
   "source": [
    "To evaluate the models, we import ``` MulticlassClassificationEvaluator ```, which will give us an accuracy metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MvoQ4iDZ3ZsW"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGIAkmlwE2gw"
   },
   "source": [
    "And we display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDrlUmce3izq",
    "outputId": "bd0209cd-2d8f-435e-c985-248a8d597447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC: 0.959731543624161 \t Features Importance: (4,[0,1,2,3],[0.010142105007278246,0.0016897828403142857,0.96352393472086,0.024644177431547582])\n",
      "RFC: 0.9664429530201343  Features Importance: (4,[0,1,2,3],[0.025437259862519997,0.024627784289245877,0.9287766018080698,0.021158354040164428])\n",
      "GBT: 0.959731543624161 \t Features Importance: (4,[0,1,2,3],[0.008071973502739728,0.03292367928105117,0.9086511641861458,0.05035318303006327])\n"
     ]
    }
   ],
   "source": [
    "print(f'DTC: {evaluator.evaluate(dtc_preds)} \\t Features Importance: {dtc_model.featureImportances}') \n",
    "print(f'RFC: {evaluator.evaluate(rfc_preds)}  Features Importance: {rfc_model.featureImportances}')\n",
    "print(f'GBT: {evaluator.evaluate(gbt_preds)} \\t Features Importance: {gbt_model.featureImportances}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XBe6MThE_Sn"
   },
   "source": [
    "As we can see, all methods have a quite similar (and quite high!) accuracy score, with the three of them coinciding in atttributing the 3rd column (**Preservative C**) an outsize influence (> 90%) on dog food spoilage. \n",
    "\n",
    "Thus, we can conclude that it is **Preservative C** which is the most responsible for Dog Food Spoilage, and we can recommend for it to stop being used."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Consulting Project: Predicting Dog Food Spoiling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
